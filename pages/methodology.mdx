# Methodology
#### Baseline 1 (Face Detection)
A baseline method we used is a direct and traditional method called Haar cascade. It is used to detect faces. Once we have the faces, we
can therefore count the individuals. We learned about Haar features 
in CS766 Computer Vision, which is used to detect human faces. Haar cascade is the machine learning (ML)
application of Haar features. The Haar cascade efficiency, simplicity, and relevancy in the course motivate us to choose this classical method. Furthermore,
the Haar cascade classifiers came with pre-trained models without the need for
additional training, which is convenient and readily accessible.

For the application of this method, we will be using the pre-trained frontal
face classifier model to determine its efficiency in crowded scenes. First, images
are converted into greyscale for processing and the pre-trained model is used to
classify the human faces. The Haar classifier can only detect clear and distinguish faces using the frontal face detection model. It detect only the eyes, 
nose, and mouth. If any of these features are not visible or distorted, it will fail to
detect as a face. To test this method, images from the ShanghaiTech images
datasets will be use.

#### Baseline 2 (Background Subtraction)
Another baseline method that we introduce is an indirect background subtraction model for crowd counting. The motivation behind this technique is
that for a surveillance camera, it is reasonable to assume an unchanging back-
ground environment (buildings, roads, etc.). Thus, if we are able to learn the
distribution of the background dataset, we can subtract any given sample frame
from the background distribution to detect anomalies, namely people for our
application. Then, we can count the number of unique objects that appear
from this resulting subtraction. The backbone of foreground/background segmentation with background modeling was introduced in Lecture 22, as shown below:

![title](/img/baseline2_method1.png)
![title](/img/baseline2_method2.png)

Given a selection of background scene images, we can learn a Gaussian Mix-
ture Model per pixel in the image. The motivation behind this is simple. We
expect a range of image scenarios (day, night, weather), and this will lead to
a multi-modal distribution across all pixel values. For our implementation, we
convert images to grayscale, so each pixel can have value 0-255. During evaluation, if a person is in the frame, the pixel value colors corresponding to the
person’s location is very unlikely to be similar to the background pixel values.
Hence, this would return a very negative log-likelihood. Using this methodology, we learn a mixture model per pixel given all the background samples and
evaluate the log-likelihoods per pixel in test images. To speed this up, we use
subsampling and simply interpolate pixel values during evaluation. We use simple thresholding to determine whether each pixel is background or foreground.
Finally, we use noise removal techniques in dilation and erosion to clean up the
result and use connected components to count the number of people in a scene. 

#### MCNN
In this approach, we intend to utilize both the Multi-column Convolutional
Neural Network (MCNN) and a two-branch Fine-grained Convolutional Neural Network (CNN) to enhance our results. To date, we have completed the
evaluation of the MCNN method.
For both these methodologies, we will utilize a Gaussian density map for
model training and for calculating both the loss and test error. This necessitates
the conversion of point-labeled data into a Gaussian density map for all training
and testing data. However, this conversion is not required for the network’s
input image unless there is a need to compute the test error. An example is shown below:

![title](/img/density_map.png)

We utilize a Multi-column Convolutional Neural Network (MCNN) architecture [3] to accurately estimate crowd count from images of arbitrary density and
perspective. The MCNN, which allows for input images of any size or resolution,
maps the image to its corresponding crowd density map. This is achieved by
employing filters with different receptive field sizes, enabling each column of the
CNN to adaptively learn features corresponding to variations in people/head
size due to perspective effect or image resolution. Furthermore, the true density
map is computed accurately based on geometry-adaptive kernels, eliminating
the need for knowledge of the perspective map of the input image. Our MCNN
comprises three columns of convolutional neural networks, each with filters of
different sizes. The input of the MCNN is the image, and its output is a crowd
density map, the integral of which provides the overall crowd count. Details of training are given in the results section. The architecture is shown below:

![title](/img/mcnn_arch.png)

#### Fine-grained CNN
We employ a fine-grained crowd counting approach [5], which differentiates
a crowd into categories based on the low-level behavior attributes of individuals
(e.g., standing/sitting or violent behavior) and then counts the number of people in each category. This approach is particularly useful in our initial target
scenario where the total number of people in an image is less informative than
the number of people in each sub-category. To effectively distinguish between
categories that have similar appearance features, we utilize a two-branch architecture consisting of a density map estimation branch and a semantic segmen-
tation branch. The density map estimation branch is responsible for the overall
crowd count, while the semantic segmentation branch handles categorization.

Except for the density map we discussed in previous model, fine-grained model has a additional semantic map in the training process. So it can give us more information about the behavior of people based on different training set.
If you train the model with “walking towards or walking away”, then the model can guess from a image how many people are walking away etc.

![](/img/fg-arch.png)
