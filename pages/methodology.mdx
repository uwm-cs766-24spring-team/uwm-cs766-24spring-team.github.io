# Methodology

## Baseline Algorithms
A baseline method we used is a direct and traditional method called Haar cascade. We learned about Haar features 
in CS766 Computer Vision, which is used to classify human faces. Haar cascade is the machine learning (ML)
application of Haar features. The Haar cascade efficiency, simplicity, and relevancy in the course motivate us to choose this classical method. Furthermore,
the Haar cascade classifiers came with pre-trained models without the need for
additional training, which is convenient and readily accessible.
Another baseline method that we introduce is an indirect background subtraction model for crowd counting. The motivation behind this technique is
that for a surveillance camera, it is reasonable to assume an unchanging back-
ground environment (buildings, roads, etc.). Thus, if we are able to learn the
distribution of the background dataset, we can subtract any given sample frame
from the background distribution to detect anomalies, namely people for our
application. Then, we can count the number of unique objects that appear
from this resulting subtraction.

## Direct
For the application of this method, we will be using the pre-trained frontal
face classifier model to determine its efficiency in crowded scenes. First, images
are converted into greyscale for processing and the pre-trained model is used to
classify the human faces. The Haar classifier can only detect clear and distinguish faces using the frontal face detection model. It detect only the eyes, 
nose, and mouth. If any of these features are not visible or distorted, it will fail to
detect as a face. To test this method, images from the ShanghaiTech images
datasets will be use.

## Indirect
Given a selection of background scene images, we can learn a Gaussian Mix-
ture Model per pixel in the image. The motivation behind this is simple. We
expect a range of image scenarios (day, night, weather), and this will lead to
a multi-modal distribution across all pixel values. For our implementation, we
convert images to grayscale, so each pixel can have value 0-255. During evaluation, if a person is in the frame, the pixel value colors corresponding to the
person’s location is very unlikely to be similar to the background pixel values.
Hence, this would return a very negative log-likelihood. Using this methodology, we learn a mixture model per pixel given all the background samples and
evaluate the log-likelihoods per pixel in test images. To speed this up, we use
subsampling and simply interpolate pixel values during evaluation. We use simple thresholding to determine whether each pixel is background or foreground.
Finally, we use noise removal techniques in dilation and erosion to clean up the
result and use connected components to count the number of people in a scene. 
 
## Neural Network
In this approach, we intend to utilize both the Multi-column Convolutional
Neural Network (MCNN) and a two-branch Fine-grained Convolutional Neural Network (CNN) to enhance our results. To date, we have completed the
evaluation of the MCNN method.
For both these methodologies, we will utilize a Gaussian density map for
model training and for calculating both the loss and test error. This necessitates
the conversion of point-labeled data into a Gaussian density map for all training
and testing data. However, this conversion is not required for the network’s
input image unless there is a need to compute the test error.

## MCNN
We utilize a Multi-column Convolutional Neural Network (MCNN) architecture [3] to accurately estimate crowd count from images of arbitrary density and
perspective. The MCNN, which allows for input images of any size or resolution,
maps the image to its corresponding crowd density map. This is achieved by
employing filters with different receptive field sizes, enabling each column of the
CNN to adaptively learn features corresponding to variations in people/head
size due to perspective effect or image resolution. Furthermore, the true density
map is computed accurately based on geometry-adaptive kernels, eliminating
the need for knowledge of the perspective map of the input image. Our MCNN
comprises three columns of convolutional neural networks, each with filters of
different sizes. The input of the MCNN is the image, and its output is a crowd
density map, the integral of which provides the overall crowd count.

## Fine-grained CNN
We employ a fine-grained crowd counting approach [5], which differentiates
a crowd into categories based on the low-level behavior attributes of individuals
(e.g., standing/sitting or violent behavior) and then counts the number of people in each category. This approach is particularly useful in our initial target
scenario where the total number of people in an image is less informative than
the number of people in each sub-category. To effectively distinguish between
categories that have similar appearance features, we utilize a two-branch architecture consisting of a density map estimation branch and a semantic segmen-
tation branch. The density map estimation branch is responsible for the overall
crowd count, while the semantic segmentation branch handles categorization.

# Initial Results
## Direct
The results depicted in Figure 1 are obtained from the direct method utilizing the Haar classifier. As illustrated in the figure, the Haar classifier is not an
optimal method to detect crowds. In crowded scenes, faces are often partially
obscured by other individuals or objects, making full face detection quite challenging. Out of these densely crowded images, it was only able to detect a few
faces and sometimes none entirely. Furthermore, it sometimes mislabeled other
objects as a face. For instance, in image 2 it classified the sign as a face. Interestingly, the classifier correctly label several human’s back inside the bounding
box. This is correct in crowd counting, but only the frontal face detection model
is used. It might be related to the inaccurate situation previously mentioned.
The model inability to detect any faces in image 1 and image 4 can be attributed
to majority of the crowd facing sideways.
Despite these limitations, it does have some advantages. As mentioned, it is
a fast and efficient method, making it a viable choice for real-time applications.
Furthermore, it also has other pre-trained models including eye detection, side
profile detection, etc. It would’ve detected even more people with its versatility
if other models were also used. However, its accuracy in crowd scenes will still
be limited due to its inability to handle occlusions.

Figure 1: Samples’ results obtained from the direct method.

## Indirect
Below are figures demonstrating the method on the PETS09 dataset.
6

Figure 2: Test image
Figure 3: Threshold result of log-likelihoods
7

Figure 4: Result after noise removal
Current quantitative results: MAE - 4.7, MSE - 33.3. From Figure 4, the
GMM performs reasonably in a surveillance setting. However, the generalization of the method must be questioned. For a dataset like ShanghaiTech, where
there are images of an entire crowd, while it will be good at capturing the crowd
density, it will be much more difficult for this method to accurately capture the
unique number of people. The problem with the connected component analysis
in this case is that closeby objects will all be counted as one person. Going forward, there are still several experiments to improve the results. Three ideas we
have are: to try adding mask on unimportant zones, to search over the threshold value and noise removal parameters, to try cleaning likelihood-map with a
gaussian blur.

### Advantages of the GMM method:
• The idea is reasonable and baseline implementation is simple
• Mixture model is flexible, can adapt to multiple scenarios (day, night,
weather, etc) for single scene which is very practical
###Disadvantages of the GMM method:
• Current implementation is very slow, not necessarily faster than NN
• Subject to tuning, so it overfits to specific scenes
• GMM must be trained per scene type, it cannot generalize given data of
a new scene
• Since this method requires a background sample for each scene to train,
it is difficult to compare this method directly with other methods using
other datasets.For example, the ShanghaiTech dataset does not have
background samples. Similarly, the PETS09 dataset does not have labels,
so it is hard to directly compare methods.

## 4.3Neural Network
### 4.3.1MCNN
We have conducted preliminary tests of this model on 10 images from the
ShanghaiTech Dataset. The current error metrics are as follows: Mean Absolute
Error (MAE) - 19.18, Mean Squared Error (MSE) - 23.96. It’s important to note
that our complete evaluation method, which is based on a Gaussian density map,
is not directly comparable with our previous methods. We plan to address this
issue in future work.
The results of this algorithm are visualized by transforming the original
images to grayscale and overlaying the density map generated by the network.
This provides a clear representation of the crowd density in each image.

(a)(b)
(c)(d)
Figure 5: Results of MCNN method


The current network is proficient at identifying the majority of individuals
in the images. However, it does have a few limitations, such as occasionally
misidentifying non-human objects as people. Despite these minor issues, the
overall performance is satisfactory. However, it falls short in discerning whether
individuals are waiting for gym equipment. To address this, we plan to implement the fine-grained, two-branch method in the future.

All members contributed equally to the various components of the project.
We each focused on a different approach:
• Lao: Direct counting methods
• William: Indirect counting methods, proofreading
• Mondo: Deep learning methods
