# Data Collection
We identified and collected three public crowd-counting datasets.
These datasets serve as the foundation for training and testing our methods.
More details about these datasets can be found in "Datasets" under "Resources."
We conducted extensive tests on various models, we also developed a new method based
on fact we can utilize background image as complementary data.

# Datasets  
We have successfully procured four distinct datasets, each exhibiting unique characteristics:  

ShanghaiTech[3]  A large dataset that includes 1198 images with about 330,000 heads annotated.  

PETS 2009[4]  The datasets comprise multi-sensor sequences containing crowd scenarios with increasing scene complexity. 
This dataset comprises data collected at various times, each associated with its corresponding background conditions.  

Fine-Grained[5]  This dataset is specifically designed for fine-grained crowd counting and includes four distinct scenarios:
Towards/Away, Standing/Sitting, Waiting/Not Waiting, and Violent/Non-violent.

VIRAT[6]  VIRAT video dataset is designed to be realistic, natural and challenging for video surveillance domains 
in terms of its resolution, background clutter, diversity in scenes, and human activity/event categories than existing 
action recognition datasets. Our intention is to utilize this dataset as we expand our algorithm to accommodate video data in future iterations.