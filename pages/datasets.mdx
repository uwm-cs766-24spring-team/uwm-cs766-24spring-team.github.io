# Datasets

We identified and collected three public crowd-counting datasets.
These datasets serve as the foundation for training and testing our methods.
More details about these datasets can be found in "Datasets" under "Resources."
We conducted extensive tests on various models, we also developed a new method based
on fact we can utilize background image as complementary data.

import { Callout, Tabs } from 'nextra/components';
import { Image } from 'next/image';

<Callout type="info">
  All datasets are available for download from the the Google Drive link we
  provided on the sidebar.
</Callout>

We have successfully procured four distinct datasets, each exhibiting unique characteristics:

<Tabs items={['ShanghaiTech', 'PETS 2009', 'Fine-Grained']}>
  <Tabs.Tab>
    <div>
      A large dataset that includes 1198 images with about 330,000 heads
      annotated.
      ![ShanghaiTech](/img/datasets/sh/IMG_1.jpg)
    </div>
    <p className="img-caption">ShanghaiTech Dataset[3]</p>
  </Tabs.Tab>
  <Tabs.Tab>
    <div>
      The datasets comprise multi-sensor sequences containing crowd scenarios with
      increasing scene complexity. This dataset comprises data collected at
      various times, each associated with its corresponding background conditions.

      ![PETS 2009](/img/datasets/pets/frame_0000.jpg)
    </div>
    <p className="img-caption">PETS 2009 Dataset[4]</p>

  </Tabs.Tab>
  <Tabs.Tab>
    <div>
      This dataset is specifically designed for fine-grained crowd counting and
      includes four distinct scenarios: Towards/Away, Standing/Sitting,
      Waiting/Not Waiting, and Violent/Non-violent.

      ![Fine-Grained](/img/datasets/fg/001.jpg)
      {/* ![Fine-Grained](/img/datasets/fg/vidf1_33_000_f001.png) */}
    </div>
    <p className="img-caption">Fine-Grained Dataset[5]. Sitting/Standing</p>

  </Tabs.Tab>
</Tabs>
