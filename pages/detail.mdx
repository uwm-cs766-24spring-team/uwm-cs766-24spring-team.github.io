## Progress  
### 2.1  Tasks Undertaken  
Since the project initiation, we have completed the following tasks:  
Literature Review and Discussion  For each method we selected, we re-  
viewed and discussed 1-2 relevant papers to deepen our understanding  
and guide our implementation.  
Data Collection  We identified and collected three public crowd-counting datasets.  
These datasets serve as the foundation for training and testing our meth-  
ods. More details about these datasets can be found in Section 2.2.  
Model Testing and Method Development  We conducted extensive tests  
on various models, we also developed a new method based on fact we can  
utilize background image as complementary data.  

### 2.2  Datasets  
We have successfully procured four distinct datasets, each exhibiting unique  
characteristics:  

ShanghaiTech[3]  A large dataset that includes 1198 images with about 330,000  
heads annotated.  

PETS 2009[4]  The datasets comprise multi-sensor sequences containing crowd  
scenarios with increasing scene complexity. This dataset comprises data  
collected at various times, each associated with its corresponding back-  
ground conditions.  

Fine-Grained[5]  This dataset is specifically designed for fine-grained crowd  
counting and includes four distinct scenarios: Towards/Away, Standing/Sitting,  
Waiting/Not Waiting, and Violent/Non-violent.  

VIRAT[6]  VIRAT video dataset is designed to be realistic, natural and chal-  
lenging for video surveillance domains in terms of its resolution, back-  
ground clutter, diversity in scenes, and human activity/event categories  
than existing action recognition datasets. Our intention is to utilize this  
dataset as we expand our algorithm to accommodate video data in future  
iterations.  

### 2.3  Related Works  
There are many approaches to computer vision (CV) crowd counting.  Al-  
though vision-based approaches from image/video data is a very natural method-  
ology, in a building environment such as a gym, there are many ingenious meth-  
ods to accurately determine how busy each floor is.  

Tracking with AP Points  The use of sensors that scan for radio signals (Blue-  
tooth and WiFi) in an area is employed in many university libraries, which  
can quickly and accurately assess floor occupancy [7].  But Wi-Fi-based  
estimates provide only a general overview of gym occupancy without of-  
fering insights into specific areas or different types of equipment usage.  
Crowd Counting using Traditional Methods  Classical CV approaches to  
crowd counting primarily rely on using video data captured from a surveil-  
lance camera or other visual sensor. These sensors then uses various tech-  
niques to detect and count individuals.  In early works, crowd counting  
work by detecting individual with bounding boxes. This is accurate in low  
density crowds. However, in overcrowded scene with severe occlusions, it  
is not optimal to detect every single person [8, 9].  

Convolutions Neural Networks  More recently, convolutions neural networks  
(CNNs) have become popular in vision-based crowd counting. Due to the  
common visual features of people in a crowd, CNNs can use this prior  
effectively to accurately understand a scene, such as [10, 11, 3].  

### 2.4  Baseline Algorithms  
A baseline method we used is a direct and traditional method called Haar  
cascade.  We learned about Haar features in CS766 Computer Vision, which  
is used to classify human faces.  Haar cascade is the machine learning (ML)  
application of Haar features. The Haar cascade efficiency, simplicity, and rele-  
vancy in the course motivate us to choose this classical method. Furthermore,  
the Haar cascade classifiers came with pre-trained models without the need for  
additional training, which is convenient and readily accessible.  
Another baseline method that we introduce is an indirect background sub-  
traction model for crowd counting.  The motivation behind this technique is  
that for a surveillance camera, it is reasonable to assume an unchanging back-  
ground environment (buildings, roads, etc.). Thus, if we are able to learn the  
distribution of the background dataset, we can subtract any given sample frame  
from the background distribution to detect anomalies, namely people for our  
application.  Then, we can count the number of unique objects that appear  
from this resulting subtraction.  

## 3  Methodology  
### 3.1  Direct  
For the application of this method, we will be using the pre-trained frontal  
face classifier model to determine its efficiency in crowded scenes. First, images  
are converted into greyscale for processing and the pre-trained model is used to  
classify the human faces. The Haar classifier can only detect clear and distin-  
guish faces using the frontal face detection model. It detect only the eyes, 
nose, and mouth.  If any of these features are not visible or distorted, it will fail to  
detect as a face.  To test this method, images from the ShanghaiTech images  
datasets will be use.  

### 3.2  Indirect  
Given a selection of background scene images, we can learn a Gaussian Mix-  
ture Model per pixel in the image. The motivation behind this is simple. We  
expect a range of image scenarios (day, night, weather), and this will lead to  
a multi-modal distribution across all pixel values. For our implementation, we  
convert images to grayscale, so each pixel can have value 0-255.  During eval-  
uation, if a person is in the frame, the pixel value colors corresponding to the  
person’s location is very unlikely to be similar to the background pixel values.  
Hence, this would return a very negative log-likelihood. Using this methodol-  
ogy, we learn a mixture model per pixel given all the background samples and  
evaluate the log-likelihoods per pixel in test images. To speed this up, we use  
subsampling and simply interpolate pixel values during evaluation. We use sim-  
ple thresholding to determine whether each pixel is background or foreground.  
Finally, we use noise removal techniques in dilation and erosion to clean up the  
result and use connected components to count the number of people in a scene. 
 
### 3.3  Neural Network  
In this approach, we intend to utilize both the Multi-column Convolutional  
Neural Network (MCNN) and a two-branch Fine-grained Convolutional Neu-  
ral Network (CNN) to enhance our results.  To date, we have completed the  
evaluation of the MCNN method.  
For both these methodologies, we will utilize a Gaussian density map for  
model training and for calculating both the loss and test error. This necessitates  
the conversion of point-labeled data into a Gaussian density map for all training  
and testing data.  However, this conversion is not required for the network’s  
input image unless there is a need to compute the test error.  

### 3.3.1  MCNN  
We utilize a Multi-column Convolutional Neural Network (MCNN) architec-  
ture [3] to accurately estimate crowd count from images of arbitrary density and  
perspective. The MCNN, which allows for input images of any size or resolution,  
maps the image to its corresponding crowd density map.  This is achieved by  
employing filters with different receptive field sizes, enabling each column of the  
CNN to adaptively learn features corresponding to variations in people/head  
size due to perspective effect or image resolution. Furthermore, the true density  
map is computed accurately based on geometry-adaptive kernels, eliminating  
the need for knowledge of the perspective map of the input image. Our MCNN  
comprises three columns of convolutional neural networks, each with filters of  
different sizes. The input of the MCNN is the image, and its output is a crowd  
density map, the integral of which provides the overall crowd count.  

### 3.3.2  Fine-grained CNN  
We employ a fine-grained crowd counting approach [5], which differentiates  
a crowd into categories based on the low-level behavior attributes of individuals  
(e.g., standing/sitting or violent behavior) and then counts the number of peo-  
ple in each category.  This approach is particularly useful in our initial target  
scenario where the total number of people in an image is less informative than  
the number of people in each sub-category. To effectively distinguish between  
categories that have similar appearance features, we utilize a two-branch archi-  
tecture consisting of a density map estimation branch and a semantic segmen-  
tation branch. The density map estimation branch is responsible for the overall  
crowd count, while the semantic segmentation branch handles categorization.  

## 4  Initial Results  
### 4.1  Direct  
The results depicted in Figure 1 are obtained from the direct method utiliz-  
ing the Haar classifier. As illustrated in the figure, the Haar classifier is not an  
optimal method to detect crowds. In crowded scenes, faces are often partially  
obscured by other individuals or objects, making full face detection quite chal-  
lenging. Out of these densely crowded images, it was only able to detect a few  
faces and sometimes none entirely. Furthermore, it sometimes mislabeled other  
objects as a face. For instance, in image 2 it classified the sign as a face. Inter-  
estingly, the classifier correctly label several human’s back inside the bounding  
box. This is correct in crowd counting, but only the frontal face detection model  
is used. It might be related to the inaccurate situation previously mentioned.  
The model inability to detect any faces in image 1 and image 4 can be attributed  
to majority of the crowd facing sideways.  
Despite these limitations, it does have some advantages. As mentioned, it is  
a fast and efficient method, making it a viable choice for real-time applications.  
Furthermore, it also has other pre-trained models including eye detection, side  
profile detection, etc. It would’ve detected even more people with its versatility  
if other models were also used. However, its accuracy in crowd scenes will still  
be limited due to its inability to handle occlusions.  
5

Figure 1: Samples’ results obtained from the direct method.  
4.2  Indirect  
Below are figures demonstrating the method on the PETS09 dataset.  
6

Figure 2: Test image  
Figure 3: Threshold result of log-likelihoods  
7

Figure 4: Result after noise removal  
Current quantitative results: MAE - 4.7, MSE - 33.3.  From Figure 4, the  
GMM performs reasonably in a surveillance setting.  However, the generaliza-  
tion of the method must be questioned. For a dataset like ShanghaiTech, where  
there are images of an entire crowd, while it will be good at capturing the crowd  
density, it will be much more difficult for this method to accurately capture the  
unique number of people. The problem with the connected component analysis  
in this case is that closeby objects will all be counted as one person. Going for-  
ward, there are still several experiments to improve the results. Three ideas we  
have are: to try adding mask on unimportant zones, to search over the thresh-  
old value and noise removal parameters, to try cleaning likelihood-map with a  
gaussian blur.  
Advantages of the GMM method:  
•  The idea is reasonable and baseline implementation is simple  
•  Mixture model is flexible, can adapt to multiple scenarios (day, night,  
weather, etc) for single scene which is very practical  
Disadvantages of the GMM method:  
•  Current implementation is very slow, not necessarily faster than NN  
•  Subject to tuning, so it overfits to specific scenes  
•  GMM must be trained per scene type, it cannot generalize given data of  
a new scene  
8

•  Since this method requires a background sample for each scene to train,  
it is difficult to compare this method directly with other methods using  
other datasets.  For example, the ShanghaiTech dataset does not have  
background samples. Similarly, the PETS09 dataset does not have labels,  
so it is hard to directly compare methods.  
## 4.3  Neural Network  
### 4.3.1  MCNN  
We have conducted preliminary tests of this model on 10 images from the  
ShanghaiTech Dataset. The current error metrics are as follows: Mean Absolute  
Error (MAE) - 19.18, Mean Squared Error (MSE) - 23.96. It’s important to note  
that our complete evaluation method, which is based on a Gaussian density map,  
is not directly comparable with our previous methods. We plan to address this  
issue in future work.  
The results of this algorithm are visualized by transforming the original  
images to grayscale and overlaying the density map generated by the network.  
This provides a clear representation of the crowd density in each image.  
bo  
(a)  (b)  
(c)  (d)  
Figure 5: Results of MCNN method  
9

The current network is proficient at identifying the majority of individuals  
in the images.  However, it does have a few limitations, such as occasionally  
misidentifying non-human objects as people.  Despite these minor issues, the  
overall performance is satisfactory. However, it falls short in discerning whether  
individuals are waiting for gym equipment. To address this, we plan to imple-  
ment the fine-grained, two-branch method in the future.  
5  Remaining Timeline  
1. Week 11: Unifying metrics and application of the Fine-Grained method.  
2. Week 12: Collection of custom test data and testing on custom test data.  
3. Week 13:  Result optimization, final visualization collection, and equip-  
ment identification.  
4. Presentation: Due on April 19.  
5. Project Webpage: Due on May 3rd.  
6  Contributions  
All members contributed equally to the various components of the project.  
We each focused on a different approach:  
•  Lao: Direct counting methods  
•  William: Indirect counting methods, proofreading  
•  Mondo: Deep learning methods  

## References  
[1] Jiwei Chen, Wen Su, and Zengfu Wang. Crowd counting with crowd atten-  
tion convolutional neural network.  Neurocomputing, 382:210–220, March 2020.  
[2] UW-Madison.  Bakke recreation center.  https://recwell.wisc.edu/bakke/.  
[3] Yingying Zhang, Desen Zhou, Siqin Chen, Shenghua Gao, and Yi Ma.  
Single-image crowd counting via multi-column convolutional neural net-  
work. In  2016 IEEE Conference on Computer Vision and Pattern Recog-  
nition (CVPR), pages 589–597, 2016.  
[4] J. Ferryman and A. Shahrokni.  Pets2009:  Dataset and challenge.  In  
2009 Twelfth IEEE International Workshop on Performance Evaluation  
of Tracking and Surveillance, pages 1–6, 2009.  
[5] Jia Wan, Nikil Senthil Kumar, and Antoni B. Chan.  Fine-grained crowd  
counting.  IEEE Transactions on Image Processing, 30:2114–2126, 2021.  
[6] VIRAT. Database version 2.0.  http://www.viratdata.org/.  
[7] OccuspaceInc.  Waitz uses custom iot sensors that scan for radio signals  
(bluetooth and wifi) in an area.  https://waitz.io/.  
[8] Zhiheng Ma, Xing Wei, Xiaopeng Hong, and Yihong Gong. Bayesian loss  
for crowd count estimation with point supervision, 2019.  
[9] Antoni B. Chan, Zhang-Sheng John Liang, and Nuno Vasconcelos.  Pri-  
vacy preserving crowd monitoring: Counting people without people models  
or tracking.  In  2008 IEEE Conference on Computer Vision and Pattern  
Recognition, pages 1–7, 2008.  
[10] Naveed Ilyas, Zaheer Ahmad, Boreom Lee, and Kiseon Kim.  An effec-  
tive modular approach for crowd counting in an image using convolutional  
neural networks.  Scientific Reports, 12(1):5795, 2022.  
[11] PapersWithCode.  Crowd  counting  benchmarks.  https:  
//paperswithcode.com/sota/crowd-counting-on-shanghaitech-b.
