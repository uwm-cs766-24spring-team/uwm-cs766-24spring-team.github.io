## Progress  
### 2.1  Tasks Undertaken  
Since the project initiation, we have completed the following tasks:  
Literature Review and Discussion  For each method we selected, we re-  
viewed and discussed 1-2 relevant papers to deepen our understanding  
and guide our implementation.  
Data Collection  We identified and collected three public crowd-counting datasets.  
These datasets serve as the foundation for training and testing our meth-  
ods. More details about these datasets can be found in Section 2.2.  
Model Testing and Method Development  We conducted extensive tests  
on various models, we also developed a new method based on fact we can  
utilize background image as complementary data.  

### 2.2  Datasets  
We have successfully procured four distinct datasets, each exhibiting unique  
characteristics:  

ShanghaiTech[3]  A large dataset that includes 1198 images with about 330,000  
heads annotated.  

PETS 2009[4]  The datasets comprise multi-sensor sequences containing crowd  
scenarios with increasing scene complexity. This dataset comprises data  
collected at various times, each associated with its corresponding back-  
ground conditions.  

Fine-Grained[5]  This dataset is specifically designed for fine-grained crowd  
counting and includes four distinct scenarios: Towards/Away, Standing/Sitting,  
Waiting/Not Waiting, and Violent/Non-violent.  

VIRAT[6]  VIRAT video dataset is designed to be realistic, natural and chal-  
lenging for video surveillance domains in terms of its resolution, back-  
ground clutter, diversity in scenes, and human activity/event categories  
than existing action recognition datasets. Our intention is to utilize this  
dataset as we expand our algorithm to accommodate video data in future  
iterations.  

### 2.3  Related Works  
There are many approaches to computer vision (CV) crowd counting.  Al-  
though vision-based approaches from image/video data is a very natural method-  
ology, in a building environment such as a gym, there are many ingenious meth-  
ods to accurately determine how busy each floor is.  

Tracking with AP Points  The use of sensors that scan for radio signals (Blue-  
tooth and WiFi) in an area is employed in many university libraries, which  
can quickly and accurately assess floor occupancy [7].  But Wi-Fi-based  
estimates provide only a general overview of gym occupancy without of-  
fering insights into specific areas or different types of equipment usage.  
Crowd Counting using Traditional Methods  Classical CV approaches to  
crowd counting primarily rely on using video data captured from a surveil-  
lance camera or other visual sensor. These sensors then uses various tech-  
niques to detect and count individuals.  In early works, crowd counting  
work by detecting individual with bounding boxes. This is accurate in low  
density crowds. However, in overcrowded scene with severe occlusions, it  
is not optimal to detect every single person [8, 9].  

Convolutions Neural Networks  More recently, convolutions neural networks  
(CNNs) have become popular in vision-based crowd counting. Due to the  
common visual features of people in a crowd, CNNs can use this prior  
effectively to accurately understand a scene, such as [10, 11, 3].  

### 2.4  Baseline Algorithms  
A baseline method we used is a direct and traditional method called Haar  
cascade.  We learned about Haar features in CS766 Computer Vision, which  
is used to classify human faces.  Haar cascade is the machine learning (ML)  
application of Haar features. The Haar cascade efficiency, simplicity, and rele-  
vancy in the course motivate us to choose this classical method. Furthermore,  
the Haar cascade classifiers came with pre-trained models without the need for  
additional training, which is convenient and readily accessible.  
Another baseline method that we introduce is an indirect background sub-  
traction model for crowd counting.  The motivation behind this technique is  
that for a surveillance camera, it is reasonable to assume an unchanging back-  
ground environment (buildings, roads, etc.). Thus, if we are able to learn the  
distribution of the background dataset, we can subtract any given sample frame  
from the background distribution to detect anomalies, namely people for our  
application.  Then, we can count the number of unique objects that appear  
from this resulting subtraction.  